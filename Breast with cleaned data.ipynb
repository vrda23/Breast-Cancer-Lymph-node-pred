{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "5aaa2a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "file = r\"C:\\Users\\jvrdo\\Downloads\\tidy_table (1).csv\"\n",
    "\n",
    "df= pd.read_csv(file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "20e5c0f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dob</th>\n",
       "      <th>velicina_tumora</th>\n",
       "      <th>hist_tip</th>\n",
       "      <th>gradus</th>\n",
       "      <th>er</th>\n",
       "      <th>pr</th>\n",
       "      <th>her2</th>\n",
       "      <th>ki67</th>\n",
       "      <th>imunofenotip</th>\n",
       "      <th>broj_meta</th>\n",
       "      <th>neo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>61</td>\n",
       "      <td>0.8</td>\n",
       "      <td>NOSinvazivnikarcinom</td>\n",
       "      <td>2</td>\n",
       "      <td>95.0</td>\n",
       "      <td>70</td>\n",
       "      <td>0.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>luminal_B</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>75</td>\n",
       "      <td>1.8</td>\n",
       "      <td>NOSinvazivnikarcinom</td>\n",
       "      <td>2</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100</td>\n",
       "      <td>3.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>luminal_B_Hp</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>65</td>\n",
       "      <td>1.2</td>\n",
       "      <td>NOSinvazivnikarcinom</td>\n",
       "      <td>2</td>\n",
       "      <td>100.0</td>\n",
       "      <td>15</td>\n",
       "      <td>3.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>luminal_B_Hp</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>71</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NOSinvazivnikarcinom</td>\n",
       "      <td>2</td>\n",
       "      <td>85.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.5</td>\n",
       "      <td>35.0</td>\n",
       "      <td>luminal_B</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>82</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NOSinvazivnikarcinom</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>3n</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8800</th>\n",
       "      <td>79</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NOSinvazivnikarcinom</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>90</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>luminal_A</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8801</th>\n",
       "      <td>80</td>\n",
       "      <td>2.9</td>\n",
       "      <td>NOSinvazivnikarcinom</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>3n</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8802</th>\n",
       "      <td>50</td>\n",
       "      <td>1.5</td>\n",
       "      <td>NOSinvazivnikarcinom</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>60</td>\n",
       "      <td>1.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>luminal_B</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8803</th>\n",
       "      <td>72</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NOSinvazivnikarcinom</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>80</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>luminal_A</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8804</th>\n",
       "      <td>68</td>\n",
       "      <td>0.6</td>\n",
       "      <td>NOSinvazivnikarcinom</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>luminal_A</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8805 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      dob  velicina_tumora              hist_tip  gradus     er   pr  her2  \\\n",
       "0      61              0.8  NOSinvazivnikarcinom       2   95.0   70   0.0   \n",
       "1      75              1.8  NOSinvazivnikarcinom       2  100.0  100   3.0   \n",
       "2      65              1.2  NOSinvazivnikarcinom       2  100.0   15   3.0   \n",
       "3      71              3.0  NOSinvazivnikarcinom       2   85.0    3   1.5   \n",
       "4      82              3.0  NOSinvazivnikarcinom       2    0.0    0   0.0   \n",
       "...   ...              ...                   ...     ...    ...  ...   ...   \n",
       "8800   79              2.0  NOSinvazivnikarcinom       1    1.0   90   1.0   \n",
       "8801   80              2.9  NOSinvazivnikarcinom       2    0.0    0   1.0   \n",
       "8802   50              1.5  NOSinvazivnikarcinom       2    1.0   60   1.0   \n",
       "8803   72              2.0  NOSinvazivnikarcinom       2    1.0   80   1.0   \n",
       "8804   68              0.6  NOSinvazivnikarcinom       2    1.0    1   1.0   \n",
       "\n",
       "      ki67  imunofenotip  broj_meta  neo  \n",
       "0     95.0     luminal_B          0    0  \n",
       "1     35.0  luminal_B_Hp          1    0  \n",
       "2     20.0  luminal_B_Hp          0    0  \n",
       "3     35.0     luminal_B          1    0  \n",
       "4     50.0            3n          1    0  \n",
       "...    ...           ...        ...  ...  \n",
       "8800  15.0     luminal_A          0    1  \n",
       "8801  50.0            3n          0    1  \n",
       "8802  22.0     luminal_B          0    1  \n",
       "8803  15.0     luminal_A          1    1  \n",
       "8804  10.0     luminal_A          0    1  \n",
       "\n",
       "[8805 rows x 11 columns]"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "f4c40801",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NOSinvazivnikarcinom               7070\n",
       "lobularniinvazivni                 1048\n",
       "mucinozniinvazivni                  202\n",
       "drugirijetkitipovi                  124\n",
       "Casmedularnimkarakteristikama        69\n",
       "mikropapilarniinvazivnikarcinom      68\n",
       "kribriformniinvazivni                67\n",
       "tubularniinvazivni                   48\n",
       "Casapokrinomdiferencijacijom         45\n",
       "metaplastičnikarcinom                44\n",
       "mikroinvazivnikarcinom               20\n",
       "Name: hist_tip, dtype: int64"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking hist types\n",
    "df[\"hist_tip\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a275038d",
   "metadata": {},
   "source": [
    "All types that are <60 in occurence will be added to \"drugi rijetki tipovi\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "08f88942",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['hist_tip'] = df['hist_tip'].replace([\"mikroinvazivnikarcinom\"],\"drugirijetkitipovi\")\n",
    "\n",
    "df['hist_tip'] = df['hist_tip'].replace([\"metaplastičnikarcinom\"],\"drugirijetkitipovi\")\n",
    "\n",
    "df['hist_tip'] = df['hist_tip'].replace([\"Casapokrinomdiferencijacijom\"],\"drugirijetkitipovi\")\n",
    "\n",
    "df['hist_tip'] = df['hist_tip'].replace([\"tubularniinvazivni\"],\"drugirijetkitipovi\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "93d92d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['hist_tip'] = df['hist_tip'].replace([\"kribriformniinvazivni\"],\"drugirijetkitipovi\")\n",
    "\n",
    "df['hist_tip'] = df['hist_tip'].replace([\"mikropapilarniinvazivnikarcinom\"],\"drugirijetkitipovi\")\n",
    "\n",
    "df['hist_tip'] = df['hist_tip'].replace([\"Casmedularnimkarakteristikama\"],\"drugirijetkitipovi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "65fa4ab7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Checking tumour size distribution\n",
    "df[\"velicina_tumora\"].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "d572aa48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a function to change some of the neoadjuvant rows that were classified as 0 metastasis to 1\n",
    "def pretvorba(df):\n",
    "    \n",
    "        if df[\"velicina_tumora\"]>3 and  df[\"neo\"]==1 and df[\"broj_meta\"]==0:\n",
    "            \n",
    "            return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "d7150b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"neo_n\"]= df.apply(lambda df: pretvorba(df), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "aa19d760",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0    75\n",
       "Name: neo_n, dtype: int64"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking how many rows did we transform\n",
    "df[\"neo_n\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "482c3cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filling new nans\n",
    "df[\"neo_n\"].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "871ed254",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dob</th>\n",
       "      <th>velicina_tumora</th>\n",
       "      <th>hist_tip</th>\n",
       "      <th>gradus</th>\n",
       "      <th>er</th>\n",
       "      <th>pr</th>\n",
       "      <th>her2</th>\n",
       "      <th>ki67</th>\n",
       "      <th>imunofenotip</th>\n",
       "      <th>broj_meta</th>\n",
       "      <th>neo</th>\n",
       "      <th>neo_n</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>61</td>\n",
       "      <td>0.8</td>\n",
       "      <td>NOSinvazivnikarcinom</td>\n",
       "      <td>2</td>\n",
       "      <td>95.0</td>\n",
       "      <td>70</td>\n",
       "      <td>0.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>luminal_B</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>75</td>\n",
       "      <td>1.8</td>\n",
       "      <td>NOSinvazivnikarcinom</td>\n",
       "      <td>2</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100</td>\n",
       "      <td>3.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>luminal_B_Hp</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>65</td>\n",
       "      <td>1.2</td>\n",
       "      <td>NOSinvazivnikarcinom</td>\n",
       "      <td>2</td>\n",
       "      <td>100.0</td>\n",
       "      <td>15</td>\n",
       "      <td>3.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>luminal_B_Hp</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>71</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NOSinvazivnikarcinom</td>\n",
       "      <td>2</td>\n",
       "      <td>85.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.5</td>\n",
       "      <td>35.0</td>\n",
       "      <td>luminal_B</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>82</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NOSinvazivnikarcinom</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>3n</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8800</th>\n",
       "      <td>79</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NOSinvazivnikarcinom</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>90</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>luminal_A</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8801</th>\n",
       "      <td>80</td>\n",
       "      <td>2.9</td>\n",
       "      <td>NOSinvazivnikarcinom</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>3n</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8802</th>\n",
       "      <td>50</td>\n",
       "      <td>1.5</td>\n",
       "      <td>NOSinvazivnikarcinom</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>60</td>\n",
       "      <td>1.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>luminal_B</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8803</th>\n",
       "      <td>72</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NOSinvazivnikarcinom</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>80</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>luminal_A</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8804</th>\n",
       "      <td>68</td>\n",
       "      <td>0.6</td>\n",
       "      <td>NOSinvazivnikarcinom</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>luminal_A</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8805 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      dob  velicina_tumora              hist_tip  gradus     er   pr  her2  \\\n",
       "0      61              0.8  NOSinvazivnikarcinom       2   95.0   70   0.0   \n",
       "1      75              1.8  NOSinvazivnikarcinom       2  100.0  100   3.0   \n",
       "2      65              1.2  NOSinvazivnikarcinom       2  100.0   15   3.0   \n",
       "3      71              3.0  NOSinvazivnikarcinom       2   85.0    3   1.5   \n",
       "4      82              3.0  NOSinvazivnikarcinom       2    0.0    0   0.0   \n",
       "...   ...              ...                   ...     ...    ...  ...   ...   \n",
       "8800   79              2.0  NOSinvazivnikarcinom       1    1.0   90   1.0   \n",
       "8801   80              2.9  NOSinvazivnikarcinom       2    0.0    0   1.0   \n",
       "8802   50              1.5  NOSinvazivnikarcinom       2    1.0   60   1.0   \n",
       "8803   72              2.0  NOSinvazivnikarcinom       2    1.0   80   1.0   \n",
       "8804   68              0.6  NOSinvazivnikarcinom       2    1.0    1   1.0   \n",
       "\n",
       "      ki67  imunofenotip  broj_meta  neo  neo_n  \n",
       "0     95.0     luminal_B          0    0    0.0  \n",
       "1     35.0  luminal_B_Hp          1    0    0.0  \n",
       "2     20.0  luminal_B_Hp          0    0    0.0  \n",
       "3     35.0     luminal_B          1    0    0.0  \n",
       "4     50.0            3n          1    0    0.0  \n",
       "...    ...           ...        ...  ...    ...  \n",
       "8800  15.0     luminal_A          0    1    0.0  \n",
       "8801  50.0            3n          0    1    0.0  \n",
       "8802  22.0     luminal_B          0    1    0.0  \n",
       "8803  15.0     luminal_A          1    1    0.0  \n",
       "8804  10.0     luminal_A          0    1    0.0  \n",
       "\n",
       "[8805 rows x 12 columns]"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "d9b0472f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filling our target with new variables\n",
    "df[\"broj_meta\"]= df[\"broj_meta\"] + df[\"neo_n\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "309aad89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    7653\n",
       "1    1152\n",
       "Name: neo, dtype: int64"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking how many neoadjuvant rows there are\n",
    "df[\"neo\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "e02db4d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping ne \"neo_n\" column (because we added the needed data to broj_meta)\n",
    "df_nov= df.drop(\"neo_n\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "02aa81c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dob</th>\n",
       "      <th>velicina_tumora</th>\n",
       "      <th>hist_tip</th>\n",
       "      <th>gradus</th>\n",
       "      <th>er</th>\n",
       "      <th>pr</th>\n",
       "      <th>her2</th>\n",
       "      <th>ki67</th>\n",
       "      <th>imunofenotip</th>\n",
       "      <th>broj_meta</th>\n",
       "      <th>neo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>61</td>\n",
       "      <td>0.8</td>\n",
       "      <td>NOSinvazivnikarcinom</td>\n",
       "      <td>2</td>\n",
       "      <td>95.0</td>\n",
       "      <td>70</td>\n",
       "      <td>0.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>luminal_B</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>75</td>\n",
       "      <td>1.8</td>\n",
       "      <td>NOSinvazivnikarcinom</td>\n",
       "      <td>2</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100</td>\n",
       "      <td>3.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>luminal_B_Hp</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>65</td>\n",
       "      <td>1.2</td>\n",
       "      <td>NOSinvazivnikarcinom</td>\n",
       "      <td>2</td>\n",
       "      <td>100.0</td>\n",
       "      <td>15</td>\n",
       "      <td>3.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>luminal_B_Hp</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>71</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NOSinvazivnikarcinom</td>\n",
       "      <td>2</td>\n",
       "      <td>85.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.5</td>\n",
       "      <td>35.0</td>\n",
       "      <td>luminal_B</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>82</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NOSinvazivnikarcinom</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>3n</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8800</th>\n",
       "      <td>79</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NOSinvazivnikarcinom</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>90</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>luminal_A</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8801</th>\n",
       "      <td>80</td>\n",
       "      <td>2.9</td>\n",
       "      <td>NOSinvazivnikarcinom</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>3n</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8802</th>\n",
       "      <td>50</td>\n",
       "      <td>1.5</td>\n",
       "      <td>NOSinvazivnikarcinom</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>60</td>\n",
       "      <td>1.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>luminal_B</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8803</th>\n",
       "      <td>72</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NOSinvazivnikarcinom</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>80</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>luminal_A</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8804</th>\n",
       "      <td>68</td>\n",
       "      <td>0.6</td>\n",
       "      <td>NOSinvazivnikarcinom</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>luminal_A</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8805 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      dob  velicina_tumora              hist_tip  gradus     er   pr  her2  \\\n",
       "0      61              0.8  NOSinvazivnikarcinom       2   95.0   70   0.0   \n",
       "1      75              1.8  NOSinvazivnikarcinom       2  100.0  100   3.0   \n",
       "2      65              1.2  NOSinvazivnikarcinom       2  100.0   15   3.0   \n",
       "3      71              3.0  NOSinvazivnikarcinom       2   85.0    3   1.5   \n",
       "4      82              3.0  NOSinvazivnikarcinom       2    0.0    0   0.0   \n",
       "...   ...              ...                   ...     ...    ...  ...   ...   \n",
       "8800   79              2.0  NOSinvazivnikarcinom       1    1.0   90   1.0   \n",
       "8801   80              2.9  NOSinvazivnikarcinom       2    0.0    0   1.0   \n",
       "8802   50              1.5  NOSinvazivnikarcinom       2    1.0   60   1.0   \n",
       "8803   72              2.0  NOSinvazivnikarcinom       2    1.0   80   1.0   \n",
       "8804   68              0.6  NOSinvazivnikarcinom       2    1.0    1   1.0   \n",
       "\n",
       "      ki67  imunofenotip  broj_meta  neo  \n",
       "0     95.0     luminal_B        0.0    0  \n",
       "1     35.0  luminal_B_Hp        1.0    0  \n",
       "2     20.0  luminal_B_Hp        0.0    0  \n",
       "3     35.0     luminal_B        1.0    0  \n",
       "4     50.0            3n        1.0    0  \n",
       "...    ...           ...        ...  ...  \n",
       "8800  15.0     luminal_A        0.0    1  \n",
       "8801  50.0            3n        0.0    1  \n",
       "8802  22.0     luminal_B        0.0    1  \n",
       "8803  15.0     luminal_A        1.0    1  \n",
       "8804  10.0     luminal_A        0.0    1  \n",
       "\n",
       "[8805 rows x 11 columns]"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking result\n",
    "df_nov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "484bc9e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    5742\n",
       "1.0    3063\n",
       "Name: broj_meta, dtype: int64"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking how many target values does our new df have\n",
    "df_nov[\"broj_meta\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "ee954092",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    5817\n",
       "1    2988\n",
       "Name: broj_meta, dtype: int64"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking old df target values for comparison \n",
    "df[\"broj_meta\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "2765e41c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a df that has no neodjuvants\n",
    "df_ne= df[df[\"neo\"]==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "8f815c29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    5314\n",
       "1    2339\n",
       "Name: broj_meta, dtype: int64"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the target in no neoadj df\n",
    "df_ne[\"broj_meta\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "e3488feb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    649\n",
       "0    503\n",
       "Name: broj_meta, dtype: int64"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking the num of targets in patients with neoadjuvant\n",
    "df_da= df[df[\"neo\"]==1]\n",
    "\n",
    "df_da[\"broj_meta\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "bc3a2c34",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8805, 10)"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking original shape\n",
    "df_c.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "f1aa3a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "import catboost as cb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from catboost import CatBoostClassifier\n",
    "from catboost import Pool, cv\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "import optuna\n",
    "from sklearn.preprocessing import OrdinalEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "6a814471",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating dummy variables for categorical columns\n",
    "df_dummies = pd.get_dummies(df_nov, columns=['hist_tip',\"imunofenotip\"], drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "id": "41f19be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test split after encoding categorical variables\n",
    "y= df_nov[\"broj_meta\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_dummies.drop(\"broj_meta\", axis=1), y, test_size = 0.15, random_state=68, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "9fd4c255",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_iterations: 4\n",
      "n_required_iterations: 4\n",
      "n_possible_iterations: 4\n",
      "min_resources_: 277\n",
      "max_resources_: 7484\n",
      "aggressive_elimination: False\n",
      "factor: 3\n",
      "----------\n",
      "iter: 0\n",
      "n_candidates: 36\n",
      "n_resources: 277\n",
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n",
      "----------\n",
      "iter: 1\n",
      "n_candidates: 12\n",
      "n_resources: 831\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "----------\n",
      "iter: 2\n",
      "n_candidates: 4\n",
      "n_resources: 2493\n",
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "----------\n",
      "iter: 3\n",
      "n_candidates: 2\n",
      "n_resources: 7479\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n"
     ]
    }
   ],
   "source": [
    "from sklearn.experimental import enable_halving_search_cv\n",
    "from sklearn.model_selection import HalvingGridSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from imblearn.ensemble import BalancedRandomForestClassifier\n",
    "\n",
    "# parameter grid\n",
    "pgrid = {    \n",
    "    'max_depth' : [75, 50],    \n",
    "    'min_samples_split' : [2,3,10],\n",
    "    'min_samples_leaf' : [1,2,10],\n",
    "    'class_weight': ['balanced','balanced_subsample']\n",
    "}\n",
    "\n",
    "# specifying the cv\n",
    "cv_skf = StratifiedKFold(n_splits=5, random_state=0, shuffle=True)\n",
    "\n",
    "# specifying the model \n",
    "rfgs = BalancedRandomForestClassifier(n_jobs=-1)\n",
    "\n",
    "\n",
    "\n",
    "# specify the grid search cv\n",
    "cv = HalvingGridSearchCV(estimator=rfgs,param_grid=pgrid,cv=cv_skf,n_jobs=-1,verbose=10, scoring='accuracy',random_state=0)\n",
    "\n",
    "cc= cv.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "991741e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'class_weight': 'balanced_subsample',\n",
       " 'max_depth': 50,\n",
       " 'min_samples_leaf': 2,\n",
       " 'min_samples_split': 10}"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking best parameters\n",
    "cc.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "id": "b5eb7d0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-29 {color: black;background-color: white;}#sk-container-id-29 pre{padding: 0;}#sk-container-id-29 div.sk-toggleable {background-color: white;}#sk-container-id-29 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-29 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-29 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-29 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-29 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-29 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-29 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-29 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-29 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-29 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-29 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-29 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-29 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-29 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-29 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-29 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-29 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-29 div.sk-item {position: relative;z-index: 1;}#sk-container-id-29 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-29 div.sk-item::before, #sk-container-id-29 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-29 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-29 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-29 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-29 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-29 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-29 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-29 div.sk-label-container {text-align: center;}#sk-container-id-29 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-29 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-29\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>BalancedRandomForestClassifier(class_weight=&#x27;balanced_subsample&#x27;, max_depth=50,\n",
       "                               min_samples_leaf=2, min_samples_split=10,\n",
       "                               n_estimators=2000, random_state=0)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-35\" type=\"checkbox\" checked><label for=\"sk-estimator-id-35\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">BalancedRandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>BalancedRandomForestClassifier(class_weight=&#x27;balanced_subsample&#x27;, max_depth=50,\n",
       "                               min_samples_leaf=2, min_samples_split=10,\n",
       "                               n_estimators=2000, random_state=0)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "BalancedRandomForestClassifier(class_weight='balanced_subsample', max_depth=50,\n",
       "                               min_samples_leaf=2, min_samples_split=10,\n",
       "                               n_estimators=2000, random_state=0)"
      ]
     },
     "execution_count": 311,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Running the optimized randomforrest\n",
    "clf_optimized = BalancedRandomForestClassifier(max_depth=50, min_samples_leaf=2, n_estimators=2000, min_samples_split=10, random_state=0,\n",
    "                                      class_weight=\"balanced_subsample\")\n",
    "clf_optimized.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "id": "720f6ae7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.25027566],\n",
       "       [0.31566439],\n",
       "       [0.25191814],\n",
       "       ...,\n",
       "       [0.83598639],\n",
       "       [0.18337211],\n",
       "       [0.31362606]])"
      ]
     },
     "execution_count": 312,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred= cc.predict_proba(X_test)\n",
    "y_pred= y_pred[:,1].reshape(-1,1)\n",
    "\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "id": "67af5e82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.27589173],\n",
       "       [0.36219903],\n",
       "       [0.2431771 ],\n",
       "       ...,\n",
       "       [0.7165229 ],\n",
       "       [0.24450279],\n",
       "       [0.35551692]])"
      ]
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_o = clf_optimized.predict_proba(X_test)\n",
    "\n",
    "y_pred_o= y_pred_o[:,1].reshape(-1,1)\n",
    "\n",
    "y_pred_o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "id": "af478111",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8983361106902994"
      ]
     },
     "execution_count": 314,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ccf12a5",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "17642dd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-22 {color: black;background-color: white;}#sk-container-id-22 pre{padding: 0;}#sk-container-id-22 div.sk-toggleable {background-color: white;}#sk-container-id-22 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-22 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-22 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-22 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-22 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-22 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-22 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-22 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-22 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-22 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-22 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-22 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-22 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-22 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-22 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-22 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-22 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-22 div.sk-item {position: relative;z-index: 1;}#sk-container-id-22 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-22 div.sk-item::before, #sk-container-id-22 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-22 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-22 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-22 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-22 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-22 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-22 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-22 div.sk-label-container {text-align: center;}#sk-container-id-22 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-22 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-22\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=0.5, booster=&#x27;gbtree&#x27;, callbacks=None,\n",
       "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric=None, gamma=0, gpu_id=0, grow_policy=&#x27;depthwise&#x27;,\n",
       "              importance_type=None, interaction_constraints=&#x27;&#x27;,\n",
       "              learning_rate=0.300000012, max_bin=256, max_cat_to_onehot=4,\n",
       "              max_delta_step=0, max_depth=6, max_leaves=0, min_child_weight=1,\n",
       "              missing=nan, monotone_constraints=&#x27;()&#x27;, n_estimators=100,\n",
       "              n_jobs=0, num_parallel_tree=1, predictor=&#x27;auto&#x27;, random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-26\" type=\"checkbox\" checked><label for=\"sk-estimator-id-26\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=0.5, booster=&#x27;gbtree&#x27;, callbacks=None,\n",
       "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric=None, gamma=0, gpu_id=0, grow_policy=&#x27;depthwise&#x27;,\n",
       "              importance_type=None, interaction_constraints=&#x27;&#x27;,\n",
       "              learning_rate=0.300000012, max_bin=256, max_cat_to_onehot=4,\n",
       "              max_delta_step=0, max_depth=6, max_leaves=0, min_child_weight=1,\n",
       "              missing=nan, monotone_constraints=&#x27;()&#x27;, n_estimators=100,\n",
       "              n_jobs=0, num_parallel_tree=1, predictor=&#x27;auto&#x27;, random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', callbacks=None,\n",
       "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric=None, gamma=0, gpu_id=0, grow_policy='depthwise',\n",
       "              importance_type=None, interaction_constraints='',\n",
       "              learning_rate=0.300000012, max_bin=256, max_cat_to_onehot=4,\n",
       "              max_delta_step=0, max_depth=6, max_leaves=0, min_child_weight=1,\n",
       "              missing=nan, monotone_constraints='()', n_estimators=100,\n",
       "              n_jobs=0, num_parallel_tree=1, predictor='auto', random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, ...)"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing XGBoost\n",
    "import xgboost as xgb\n",
    "\n",
    "# Initiating XGBoost classifier\n",
    "xgc = xgb.XGBClassifier(\n",
    "    tree_method=\"gpu_hist\"\n",
    ")\n",
    "\n",
    "# Fitting the model\n",
    "xgc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "b54ed9be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.2980141 ],\n",
       "       [0.2104606 ],\n",
       "       [0.7193604 ],\n",
       "       ...,\n",
       "       [0.04456395],\n",
       "       [0.1493421 ],\n",
       "       [0.34748745]], dtype=float32)"
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Baseline XBG predictions\n",
    "y_pred_x= xgc.predict_proba(X_test)\n",
    "\n",
    "y_pred_x= y_pred_x[:,1].reshape(-1,1)\n",
    "\n",
    "y_pred_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "2ad64146",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6962777164130257"
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Baseline XGB score\n",
    "roc_auc_score(y_test, y_pred_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "78569539",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
      "20 fits failed out of a total of 60.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [18:34:23] c:\\users\\administrator\\workspace\\xgboost-win64_release_1.6.0\\src\\data\\../common/device_helpers.cuh:428: Memory allocation error on worker 0: Caching allocator\n",
      "- Free memory: 15965618176\n",
      "- Requested memory: 34359738352\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [18:34:37] c:\\users\\administrator\\workspace\\xgboost-win64_release_1.6.0\\src\\data\\../common/device_helpers.cuh:428: Memory allocation error on worker 0: Caching allocator\n",
      "- Free memory: 15965618176\n",
      "- Requested memory: 34359738352\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [18:34:48] c:\\users\\administrator\\workspace\\xgboost-win64_release_1.6.0\\src\\data\\../common/device_helpers.cuh:428: Memory allocation error on worker 0: Caching allocator\n",
      "- Free memory: 15967715328\n",
      "- Requested memory: 34359738352\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [18:34:58] c:\\users\\administrator\\workspace\\xgboost-win64_release_1.6.0\\src\\data\\../common/device_helpers.cuh:428: Memory allocation error on worker 0: Caching allocator\n",
      "- Free memory: 15965618176\n",
      "- Requested memory: 34359738352\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [18:35:11] c:\\users\\administrator\\workspace\\xgboost-win64_release_1.6.0\\src\\data\\../common/device_helpers.cuh:428: Memory allocation error on worker 0: Caching allocator\n",
      "- Free memory: 15965618176\n",
      "- Requested memory: 34359738352\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [18:39:03] c:\\users\\administrator\\workspace\\xgboost-win64_release_1.6.0\\src\\data\\../common/device_helpers.cuh:428: Memory allocation error on worker 0: Caching allocator\n",
      "- Free memory: 15965618176\n",
      "- Requested memory: 34359738352\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [18:39:16] c:\\users\\administrator\\workspace\\xgboost-win64_release_1.6.0\\src\\data\\../common/device_helpers.cuh:428: Memory allocation error on worker 0: Caching allocator\n",
      "- Free memory: 15967715328\n",
      "- Requested memory: 34359738352\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [18:39:29] c:\\users\\administrator\\workspace\\xgboost-win64_release_1.6.0\\src\\data\\../common/device_helpers.cuh:428: Memory allocation error on worker 0: Caching allocator\n",
      "- Free memory: 15965618176\n",
      "- Requested memory: 34359738352\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [18:39:42] c:\\users\\administrator\\workspace\\xgboost-win64_release_1.6.0\\src\\data\\../common/device_helpers.cuh:428: Memory allocation error on worker 0: Caching allocator\n",
      "- Free memory: 15967715328\n",
      "- Requested memory: 34359738352\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [18:39:55] c:\\users\\administrator\\workspace\\xgboost-win64_release_1.6.0\\src\\data\\../common/device_helpers.cuh:428: Memory allocation error on worker 0: Caching allocator\n",
      "- Free memory: 15967715328\n",
      "- Requested memory: 34359738352\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [18:45:04] c:\\users\\administrator\\workspace\\xgboost-win64_release_1.6.0\\src\\data\\../common/device_helpers.cuh:428: Memory allocation error on worker 0: Caching allocator\n",
      "- Free memory: 15965618176\n",
      "- Requested memory: 34359738352\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [18:45:18] c:\\users\\administrator\\workspace\\xgboost-win64_release_1.6.0\\src\\data\\../common/device_helpers.cuh:428: Memory allocation error on worker 0: Caching allocator\n",
      "- Free memory: 15965618176\n",
      "- Requested memory: 34359738352\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [18:45:29] c:\\users\\administrator\\workspace\\xgboost-win64_release_1.6.0\\src\\data\\../common/device_helpers.cuh:428: Memory allocation error on worker 0: Caching allocator\n",
      "- Free memory: 15965618176\n",
      "- Requested memory: 34359738352\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [18:45:40] c:\\users\\administrator\\workspace\\xgboost-win64_release_1.6.0\\src\\data\\../common/device_helpers.cuh:428: Memory allocation error on worker 0: Caching allocator\n",
      "- Free memory: 15965618176\n",
      "- Requested memory: 34359738352\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [18:45:53] c:\\users\\administrator\\workspace\\xgboost-win64_release_1.6.0\\src\\data\\../common/device_helpers.cuh:428: Memory allocation error on worker 0: Caching allocator\n",
      "- Free memory: 15965618176\n",
      "- Requested memory: 34359738352\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [18:50:55] c:\\users\\administrator\\workspace\\xgboost-win64_release_1.6.0\\src\\data\\../common/device_helpers.cuh:428: Memory allocation error on worker 0: Caching allocator\n",
      "- Free memory: 15965618176\n",
      "- Requested memory: 34359738352\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [18:51:06] c:\\users\\administrator\\workspace\\xgboost-win64_release_1.6.0\\src\\data\\../common/device_helpers.cuh:428: Memory allocation error on worker 0: Caching allocator\n",
      "- Free memory: 15965618176\n",
      "- Requested memory: 34359738352\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [18:51:16] c:\\users\\administrator\\workspace\\xgboost-win64_release_1.6.0\\src\\data\\../common/device_helpers.cuh:428: Memory allocation error on worker 0: Caching allocator\n",
      "- Free memory: 15965618176\n",
      "- Requested memory: 34359738352\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [18:51:29] c:\\users\\administrator\\workspace\\xgboost-win64_release_1.6.0\\src\\data\\../common/device_helpers.cuh:428: Memory allocation error on worker 0: Caching allocator\n",
      "- Free memory: 15965618176\n",
      "- Requested memory: 34359738352\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [18:51:41] c:\\users\\administrator\\workspace\\xgboost-win64_release_1.6.0\\src\\data\\../common/device_helpers.cuh:428: Memory allocation error on worker 0: Caching allocator\n",
      "- Free memory: 15961423872\n",
      "- Requested memory: 34359738352\n",
      "\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:953: UserWarning: One or more of the test scores are non-finite: [0.73038959 0.72400538        nan 0.73041706 0.72507688        nan\n",
      " 0.72643762 0.71834109        nan 0.72536239 0.71864056        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-23 {color: black;background-color: white;}#sk-container-id-23 pre{padding: 0;}#sk-container-id-23 div.sk-toggleable {background-color: white;}#sk-container-id-23 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-23 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-23 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-23 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-23 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-23 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-23 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-23 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-23 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-23 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-23 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-23 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-23 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-23 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-23 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-23 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-23 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-23 div.sk-item {position: relative;z-index: 1;}#sk-container-id-23 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-23 div.sk-item::before, #sk-container-id-23 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-23 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-23 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-23 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-23 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-23 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-23 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-23 div.sk-label-container {text-align: center;}#sk-container-id-23 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-23 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-23\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=0, shuffle=True),\n",
       "             estimator=XGBClassifier(base_score=0.5, booster=&#x27;gbtree&#x27;,\n",
       "                                     callbacks=None, colsample_bylevel=1,\n",
       "                                     colsample_bynode=1, colsample_bytree=1,\n",
       "                                     early_stopping_rounds=None,\n",
       "                                     enable_categorical=False, eval_metric=None,\n",
       "                                     gamma=0, gpu_id=0, grow_policy=&#x27;depthwise&#x27;,\n",
       "                                     importance_type=None,\n",
       "                                     interaction_constr...\n",
       "                                     max_depth=6, max_leaves=0,\n",
       "                                     min_child_weight=1, missing=nan,\n",
       "                                     monotone_constraints=&#x27;()&#x27;,\n",
       "                                     n_estimators=100, n_jobs=0,\n",
       "                                     num_parallel_tree=1, predictor=&#x27;auto&#x27;,\n",
       "                                     random_state=0, reg_alpha=0, reg_lambda=1, ...),\n",
       "             param_grid={&#x27;colsample_bylevel&#x27;: [0.5, 0.7],\n",
       "                         &#x27;colsample_bytree&#x27;: [0.5, 0.4],\n",
       "                         &#x27;learning_rate&#x27;: [0.01], &#x27;max_depth&#x27;: [10, 15, 30],\n",
       "                         &#x27;n_estimators&#x27;: [1000]},\n",
       "             scoring=&#x27;roc_auc&#x27;, verbose=-1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-27\" type=\"checkbox\" ><label for=\"sk-estimator-id-27\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=0, shuffle=True),\n",
       "             estimator=XGBClassifier(base_score=0.5, booster=&#x27;gbtree&#x27;,\n",
       "                                     callbacks=None, colsample_bylevel=1,\n",
       "                                     colsample_bynode=1, colsample_bytree=1,\n",
       "                                     early_stopping_rounds=None,\n",
       "                                     enable_categorical=False, eval_metric=None,\n",
       "                                     gamma=0, gpu_id=0, grow_policy=&#x27;depthwise&#x27;,\n",
       "                                     importance_type=None,\n",
       "                                     interaction_constr...\n",
       "                                     max_depth=6, max_leaves=0,\n",
       "                                     min_child_weight=1, missing=nan,\n",
       "                                     monotone_constraints=&#x27;()&#x27;,\n",
       "                                     n_estimators=100, n_jobs=0,\n",
       "                                     num_parallel_tree=1, predictor=&#x27;auto&#x27;,\n",
       "                                     random_state=0, reg_alpha=0, reg_lambda=1, ...),\n",
       "             param_grid={&#x27;colsample_bylevel&#x27;: [0.5, 0.7],\n",
       "                         &#x27;colsample_bytree&#x27;: [0.5, 0.4],\n",
       "                         &#x27;learning_rate&#x27;: [0.01], &#x27;max_depth&#x27;: [10, 15, 30],\n",
       "                         &#x27;n_estimators&#x27;: [1000]},\n",
       "             scoring=&#x27;roc_auc&#x27;, verbose=-1)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-28\" type=\"checkbox\" ><label for=\"sk-estimator-id-28\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=0.5, booster=&#x27;gbtree&#x27;, callbacks=None,\n",
       "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric=None, gamma=0, gpu_id=0, grow_policy=&#x27;depthwise&#x27;,\n",
       "              importance_type=None, interaction_constraints=&#x27;&#x27;,\n",
       "              learning_rate=0.300000012, max_bin=256, max_cat_to_onehot=4,\n",
       "              max_delta_step=0, max_depth=6, max_leaves=0, min_child_weight=1,\n",
       "              missing=nan, monotone_constraints=&#x27;()&#x27;, n_estimators=100,\n",
       "              n_jobs=0, num_parallel_tree=1, predictor=&#x27;auto&#x27;, random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, ...)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-29\" type=\"checkbox\" ><label for=\"sk-estimator-id-29\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=0.5, booster=&#x27;gbtree&#x27;, callbacks=None,\n",
       "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric=None, gamma=0, gpu_id=0, grow_policy=&#x27;depthwise&#x27;,\n",
       "              importance_type=None, interaction_constraints=&#x27;&#x27;,\n",
       "              learning_rate=0.300000012, max_bin=256, max_cat_to_onehot=4,\n",
       "              max_delta_step=0, max_depth=6, max_leaves=0, min_child_weight=1,\n",
       "              missing=nan, monotone_constraints=&#x27;()&#x27;, n_estimators=100,\n",
       "              n_jobs=0, num_parallel_tree=1, predictor=&#x27;auto&#x27;, random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, ...)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=0, shuffle=True),\n",
       "             estimator=XGBClassifier(base_score=0.5, booster='gbtree',\n",
       "                                     callbacks=None, colsample_bylevel=1,\n",
       "                                     colsample_bynode=1, colsample_bytree=1,\n",
       "                                     early_stopping_rounds=None,\n",
       "                                     enable_categorical=False, eval_metric=None,\n",
       "                                     gamma=0, gpu_id=0, grow_policy='depthwise',\n",
       "                                     importance_type=None,\n",
       "                                     interaction_constr...\n",
       "                                     max_depth=6, max_leaves=0,\n",
       "                                     min_child_weight=1, missing=nan,\n",
       "                                     monotone_constraints='()',\n",
       "                                     n_estimators=100, n_jobs=0,\n",
       "                                     num_parallel_tree=1, predictor='auto',\n",
       "                                     random_state=0, reg_alpha=0, reg_lambda=1, ...),\n",
       "             param_grid={'colsample_bylevel': [0.5, 0.7],\n",
       "                         'colsample_bytree': [0.5, 0.4],\n",
       "                         'learning_rate': [0.01], 'max_depth': [10, 15, 30],\n",
       "                         'n_estimators': [1000]},\n",
       "             scoring='roc_auc', verbose=-1)"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing Grid search \n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Setting out parameter values\n",
    "params = { 'max_depth': [10, 15, 30],\n",
    "           'learning_rate': [0.01],\n",
    "           'n_estimators': [1000],\n",
    "           'colsample_bytree': [0.5, 0.4],\n",
    "         'colsample_bylevel': [0.5, 0.7]}\n",
    "\n",
    "\n",
    "# Initiating GridSearch CV\n",
    "clf = GridSearchCV(estimator=xgc, \n",
    "                   param_grid=params,\n",
    "                   cv=cv_skf,\n",
    "                   scoring='roc_auc', \n",
    "                   verbose=-1)\n",
    "# Fitting GridSearch to our training data\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "5fbfc67a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'colsample_bylevel': 0.5, 'colsample_bytree': 0.4, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 1000}\n"
     ]
    }
   ],
   "source": [
    "print(\"Best parameters:\", clf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "id": "7ea34b32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-28 {color: black;background-color: white;}#sk-container-id-28 pre{padding: 0;}#sk-container-id-28 div.sk-toggleable {background-color: white;}#sk-container-id-28 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-28 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-28 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-28 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-28 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-28 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-28 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-28 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-28 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-28 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-28 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-28 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-28 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-28 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-28 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-28 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-28 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-28 div.sk-item {position: relative;z-index: 1;}#sk-container-id-28 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-28 div.sk-item::before, #sk-container-id-28 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-28 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-28 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-28 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-28 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-28 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-28 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-28 div.sk-label-container {text-align: center;}#sk-container-id-28 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-28 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-28\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=0.5, booster=&#x27;gbtree&#x27;, callbacks=None,\n",
       "              colsample_bylevel=0.5, colsample_bynode=1, colsample_bytree=0.4,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric=None, gamma=0, gpu_id=0, grow_policy=&#x27;depthwise&#x27;,\n",
       "              importance_type=None, interaction_constraints=&#x27;&#x27;,\n",
       "              learning_rate=0.01, max_bin=256, max_cat_to_onehot=4,\n",
       "              max_delta_step=0, max_depth=10, max_leaves=0, min_child_weight=1,\n",
       "              missing=nan, monotone_constraints=&#x27;()&#x27;, n_estimators=1000,\n",
       "              n_jobs=0, num_parallel_tree=1, predictor=&#x27;auto&#x27;, random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-34\" type=\"checkbox\" checked><label for=\"sk-estimator-id-34\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=0.5, booster=&#x27;gbtree&#x27;, callbacks=None,\n",
       "              colsample_bylevel=0.5, colsample_bynode=1, colsample_bytree=0.4,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric=None, gamma=0, gpu_id=0, grow_policy=&#x27;depthwise&#x27;,\n",
       "              importance_type=None, interaction_constraints=&#x27;&#x27;,\n",
       "              learning_rate=0.01, max_bin=256, max_cat_to_onehot=4,\n",
       "              max_delta_step=0, max_depth=10, max_leaves=0, min_child_weight=1,\n",
       "              missing=nan, monotone_constraints=&#x27;()&#x27;, n_estimators=1000,\n",
       "              n_jobs=0, num_parallel_tree=1, predictor=&#x27;auto&#x27;, random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', callbacks=None,\n",
       "              colsample_bylevel=0.5, colsample_bynode=1, colsample_bytree=0.4,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric=None, gamma=0, gpu_id=0, grow_policy='depthwise',\n",
       "              importance_type=None, interaction_constraints='',\n",
       "              learning_rate=0.01, max_bin=256, max_cat_to_onehot=4,\n",
       "              max_delta_step=0, max_depth=10, max_leaves=0, min_child_weight=1,\n",
       "              missing=nan, monotone_constraints='()', n_estimators=1000,\n",
       "              n_jobs=0, num_parallel_tree=1, predictor='auto', random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, ...)"
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initiating optimized version\n",
    "xgc = xgb.XGBClassifier(\n",
    "    tree_method=\"gpu_hist\", colsample_bylevel=0.5, colsample_bytree=0.4, learning_rate=0.01, max_depth=10, n_estimators=1000\n",
    ")\n",
    "\n",
    "# Fitting the model\n",
    "xgc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "id": "297ea833",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.14457402],\n",
       "       [0.21168607],\n",
       "       [0.1582005 ],\n",
       "       ...,\n",
       "       [0.68578655],\n",
       "       [0.16101585],\n",
       "       [0.20505308]], dtype=float32)"
      ]
     },
     "execution_count": 309,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Optimized XBG predictions\n",
    "y_pred_xo= xgc.predict_proba(X_test)\n",
    "\n",
    "y_pred_xo= y_pred_xo[:,1].reshape(-1,1)\n",
    "\n",
    "y_pred_xo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "id": "cf2ce0cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7629879311215473"
      ]
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Optimized XGB score\n",
    "roc_auc_score(y_test, y_pred_xo)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e46dead0",
   "metadata": {},
   "source": [
    "## Model bez neoadjuvantnih"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "8b7e99d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dummies = pd.get_dummies(df_ne, columns=['hist_tip',\"imunofenotip\"], drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "3b39b2b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test split after encoding categorical variables\n",
    "y= df_ne[\"broj_meta\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_dummies.drop(\"broj_meta\", axis=1), y, test_size = 0.15, random_state=68, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "bd82ce16",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
      "40 fits failed out of a total of 80.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [10:59:20] c:\\users\\administrator\\workspace\\xgboost-win64_release_1.6.0\\src\\data\\../common/device_helpers.cuh:428: Memory allocation error on worker 0: Caching allocator\n",
      "- Free memory: 15969812480\n",
      "- Requested memory: 34359738352\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [10:59:33] c:\\users\\administrator\\workspace\\xgboost-win64_release_1.6.0\\src\\data\\../common/device_helpers.cuh:428: Memory allocation error on worker 0: Caching allocator\n",
      "- Free memory: 15967715328\n",
      "- Requested memory: 34359738352\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [10:59:46] c:\\users\\administrator\\workspace\\xgboost-win64_release_1.6.0\\src\\data\\../common/device_helpers.cuh:428: Memory allocation error on worker 0: Caching allocator\n",
      "- Free memory: 15967715328\n",
      "- Requested memory: 34359738352\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [10:59:59] c:\\users\\administrator\\workspace\\xgboost-win64_release_1.6.0\\src\\data\\../common/device_helpers.cuh:428: Memory allocation error on worker 0: Caching allocator\n",
      "- Free memory: 15969812480\n",
      "- Requested memory: 34359738352\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [11:00:12] c:\\users\\administrator\\workspace\\xgboost-win64_release_1.6.0\\src\\data\\../common/device_helpers.cuh:428: Memory allocation error on worker 0: Caching allocator\n",
      "- Free memory: 15967715328\n",
      "- Requested memory: 34359738352\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [11:00:22] c:\\users\\administrator\\workspace\\xgboost-win64_release_1.6.0\\src\\data\\../common/device_helpers.cuh:428: Memory allocation error on worker 0: Caching allocator\n",
      "- Free memory: 15969812480\n",
      "- Requested memory: 34359738352\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [11:00:32] c:\\users\\administrator\\workspace\\xgboost-win64_release_1.6.0\\src\\data\\../common/device_helpers.cuh:428: Memory allocation error on worker 0: Caching allocator\n",
      "- Free memory: 15967715328\n",
      "- Requested memory: 34359738352\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [11:00:45] c:\\users\\administrator\\workspace\\xgboost-win64_release_1.6.0\\src\\data\\../common/device_helpers.cuh:428: Memory allocation error on worker 0: Caching allocator\n",
      "- Free memory: 15967715328\n",
      "- Requested memory: 34359738352\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [11:00:57] c:\\users\\administrator\\workspace\\xgboost-win64_release_1.6.0\\src\\data\\../common/device_helpers.cuh:428: Memory allocation error on worker 0: Caching allocator\n",
      "- Free memory: 15969812480\n",
      "- Requested memory: 34359738352\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [11:01:10] c:\\users\\administrator\\workspace\\xgboost-win64_release_1.6.0\\src\\data\\../common/device_helpers.cuh:428: Memory allocation error on worker 0: Caching allocator\n",
      "- Free memory: 15967715328\n",
      "- Requested memory: 34359738352\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [11:03:33] c:\\users\\administrator\\workspace\\xgboost-win64_release_1.6.0\\src\\data\\../common/device_helpers.cuh:428: Memory allocation error on worker 0: Caching allocator\n",
      "- Free memory: 15967715328\n",
      "- Requested memory: 34359738352\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [11:03:46] c:\\users\\administrator\\workspace\\xgboost-win64_release_1.6.0\\src\\data\\../common/device_helpers.cuh:428: Memory allocation error on worker 0: Caching allocator\n",
      "- Free memory: 15969812480\n",
      "- Requested memory: 34359738352\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [11:03:59] c:\\users\\administrator\\workspace\\xgboost-win64_release_1.6.0\\src\\data\\../common/device_helpers.cuh:428: Memory allocation error on worker 0: Caching allocator\n",
      "- Free memory: 15969812480\n",
      "- Requested memory: 34359738352\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [11:04:12] c:\\users\\administrator\\workspace\\xgboost-win64_release_1.6.0\\src\\data\\../common/device_helpers.cuh:428: Memory allocation error on worker 0: Caching allocator\n",
      "- Free memory: 15967715328\n",
      "- Requested memory: 34359738352\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [11:04:24] c:\\users\\administrator\\workspace\\xgboost-win64_release_1.6.0\\src\\data\\../common/device_helpers.cuh:428: Memory allocation error on worker 0: Caching allocator\n",
      "- Free memory: 15967715328\n",
      "- Requested memory: 34359738352\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [11:04:35] c:\\users\\administrator\\workspace\\xgboost-win64_release_1.6.0\\src\\data\\../common/device_helpers.cuh:428: Memory allocation error on worker 0: Caching allocator\n",
      "- Free memory: 15967715328\n",
      "- Requested memory: 34359738352\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [11:04:47] c:\\users\\administrator\\workspace\\xgboost-win64_release_1.6.0\\src\\data\\../common/device_helpers.cuh:428: Memory allocation error on worker 0: Caching allocator\n",
      "- Free memory: 15969812480\n",
      "- Requested memory: 34359738352\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [11:05:00] c:\\users\\administrator\\workspace\\xgboost-win64_release_1.6.0\\src\\data\\../common/device_helpers.cuh:428: Memory allocation error on worker 0: Caching allocator\n",
      "- Free memory: 15969812480\n",
      "- Requested memory: 34359738352\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [11:05:10] c:\\users\\administrator\\workspace\\xgboost-win64_release_1.6.0\\src\\data\\../common/device_helpers.cuh:428: Memory allocation error on worker 0: Caching allocator\n",
      "- Free memory: 15967715328\n",
      "- Requested memory: 34359738352\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [11:05:23] c:\\users\\administrator\\workspace\\xgboost-win64_release_1.6.0\\src\\data\\../common/device_helpers.cuh:428: Memory allocation error on worker 0: Caching allocator\n",
      "- Free memory: 15967715328\n",
      "- Requested memory: 34359738352\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [11:08:36] c:\\users\\administrator\\workspace\\xgboost-win64_release_1.6.0\\src\\data\\../common/device_helpers.cuh:428: Memory allocation error on worker 0: Caching allocator\n",
      "- Free memory: 15965618176\n",
      "- Requested memory: 34359738352\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [11:08:49] c:\\users\\administrator\\workspace\\xgboost-win64_release_1.6.0\\src\\data\\../common/device_helpers.cuh:428: Memory allocation error on worker 0: Caching allocator\n",
      "- Free memory: 15965618176\n",
      "- Requested memory: 34359738352\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [11:09:02] c:\\users\\administrator\\workspace\\xgboost-win64_release_1.6.0\\src\\data\\../common/device_helpers.cuh:428: Memory allocation error on worker 0: Caching allocator\n",
      "- Free memory: 15965618176\n",
      "- Requested memory: 34359738352\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [11:09:15] c:\\users\\administrator\\workspace\\xgboost-win64_release_1.6.0\\src\\data\\../common/device_helpers.cuh:428: Memory allocation error on worker 0: Caching allocator\n",
      "- Free memory: 15965618176\n",
      "- Requested memory: 34359738352\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [11:09:26] c:\\users\\administrator\\workspace\\xgboost-win64_release_1.6.0\\src\\data\\../common/device_helpers.cuh:428: Memory allocation error on worker 0: Caching allocator\n",
      "- Free memory: 15965618176\n",
      "- Requested memory: 34359738352\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [11:09:36] c:\\users\\administrator\\workspace\\xgboost-win64_release_1.6.0\\src\\data\\../common/device_helpers.cuh:428: Memory allocation error on worker 0: Caching allocator\n",
      "- Free memory: 15965618176\n",
      "- Requested memory: 34359738352\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [11:09:49] c:\\users\\administrator\\workspace\\xgboost-win64_release_1.6.0\\src\\data\\../common/device_helpers.cuh:428: Memory allocation error on worker 0: Caching allocator\n",
      "- Free memory: 15965618176\n",
      "- Requested memory: 34359738352\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [11:10:00] c:\\users\\administrator\\workspace\\xgboost-win64_release_1.6.0\\src\\data\\../common/device_helpers.cuh:428: Memory allocation error on worker 0: Caching allocator\n",
      "- Free memory: 15965618176\n",
      "- Requested memory: 34359738352\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [11:10:10] c:\\users\\administrator\\workspace\\xgboost-win64_release_1.6.0\\src\\data\\../common/device_helpers.cuh:428: Memory allocation error on worker 0: Caching allocator\n",
      "- Free memory: 15965618176\n",
      "- Requested memory: 34359738352\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [11:10:23] c:\\users\\administrator\\workspace\\xgboost-win64_release_1.6.0\\src\\data\\../common/device_helpers.cuh:428: Memory allocation error on worker 0: Caching allocator\n",
      "- Free memory: 15965618176\n",
      "- Requested memory: 34359738352\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [11:13:13] c:\\users\\administrator\\workspace\\xgboost-win64_release_1.6.0\\src\\data\\../common/device_helpers.cuh:428: Memory allocation error on worker 0: Caching allocator\n",
      "- Free memory: 15967715328\n",
      "- Requested memory: 34359738352\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [11:13:24] c:\\users\\administrator\\workspace\\xgboost-win64_release_1.6.0\\src\\data\\../common/device_helpers.cuh:428: Memory allocation error on worker 0: Caching allocator\n",
      "- Free memory: 15967715328\n",
      "- Requested memory: 34359738352\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [11:13:37] c:\\users\\administrator\\workspace\\xgboost-win64_release_1.6.0\\src\\data\\../common/device_helpers.cuh:428: Memory allocation error on worker 0: Caching allocator\n",
      "- Free memory: 15967715328\n",
      "- Requested memory: 34359738352\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [11:13:50] c:\\users\\administrator\\workspace\\xgboost-win64_release_1.6.0\\src\\data\\../common/device_helpers.cuh:428: Memory allocation error on worker 0: Caching allocator\n",
      "- Free memory: 15967715328\n",
      "- Requested memory: 34359738352\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [11:14:03] c:\\users\\administrator\\workspace\\xgboost-win64_release_1.6.0\\src\\data\\../common/device_helpers.cuh:428: Memory allocation error on worker 0: Caching allocator\n",
      "- Free memory: 15967715328\n",
      "- Requested memory: 34359738352\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [11:14:13] c:\\users\\administrator\\workspace\\xgboost-win64_release_1.6.0\\src\\data\\../common/device_helpers.cuh:428: Memory allocation error on worker 0: Caching allocator\n",
      "- Free memory: 15967715328\n",
      "- Requested memory: 34359738352\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [11:14:26] c:\\users\\administrator\\workspace\\xgboost-win64_release_1.6.0\\src\\data\\../common/device_helpers.cuh:428: Memory allocation error on worker 0: Caching allocator\n",
      "- Free memory: 15967715328\n",
      "- Requested memory: 34359738352\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [11:14:39] c:\\users\\administrator\\workspace\\xgboost-win64_release_1.6.0\\src\\data\\../common/device_helpers.cuh:428: Memory allocation error on worker 0: Caching allocator\n",
      "- Free memory: 15967715328\n",
      "- Requested memory: 34359738352\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [11:14:52] c:\\users\\administrator\\workspace\\xgboost-win64_release_1.6.0\\src\\data\\../common/device_helpers.cuh:428: Memory allocation error on worker 0: Caching allocator\n",
      "- Free memory: 15967715328\n",
      "- Requested memory: 34359738352\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [11:15:02] c:\\users\\administrator\\workspace\\xgboost-win64_release_1.6.0\\src\\data\\../common/device_helpers.cuh:428: Memory allocation error on worker 0: Caching allocator\n",
      "- Free memory: 15967715328\n",
      "- Requested memory: 34359738352\n",
      "\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\jvrdo\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:953: UserWarning: One or more of the test scores are non-finite: [0.71532359 0.70707881        nan        nan 0.71999314 0.71320338\n",
      "        nan        nan 0.71070516 0.70262587        nan        nan\n",
      " 0.71487323 0.70746483        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-12 {color: black;background-color: white;}#sk-container-id-12 pre{padding: 0;}#sk-container-id-12 div.sk-toggleable {background-color: white;}#sk-container-id-12 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-12 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-12 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-12 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-12 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-12 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-12 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-12 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-12 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-12 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-12 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-12 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-12 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-12 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-12 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-12 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-12 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-12 div.sk-item {position: relative;z-index: 1;}#sk-container-id-12 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-12 div.sk-item::before, #sk-container-id-12 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-12 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-12 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-12 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-12 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-12 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-12 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-12 div.sk-label-container {text-align: center;}#sk-container-id-12 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-12 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-12\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=0, shuffle=True),\n",
       "             estimator=XGBClassifier(base_score=0.5, booster=&#x27;gbtree&#x27;,\n",
       "                                     callbacks=None, colsample_bylevel=0.5,\n",
       "                                     colsample_bynode=1, colsample_bytree=0.4,\n",
       "                                     early_stopping_rounds=None,\n",
       "                                     enable_categorical=False, eval_metric=None,\n",
       "                                     gamma=0, gpu_id=0, grow_policy=&#x27;depthwise&#x27;,\n",
       "                                     importance_type=None,\n",
       "                                     interaction_co...\n",
       "                                     max_depth=10, max_leaves=0,\n",
       "                                     min_child_weight=1, missing=nan,\n",
       "                                     monotone_constraints=&#x27;()&#x27;,\n",
       "                                     n_estimators=1000, n_jobs=0,\n",
       "                                     num_parallel_tree=1, predictor=&#x27;auto&#x27;,\n",
       "                                     random_state=0, reg_alpha=0, reg_lambda=1, ...),\n",
       "             param_grid={&#x27;colsample_bylevel&#x27;: [0.5, 0.7],\n",
       "                         &#x27;colsample_bytree&#x27;: [0.5, 0.4],\n",
       "                         &#x27;learning_rate&#x27;: [0.01], &#x27;max_depth&#x27;: [10, 30],\n",
       "                         &#x27;n_estimators&#x27;: [1000, 1500]},\n",
       "             scoring=&#x27;roc_auc&#x27;, verbose=-1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-14\" type=\"checkbox\" ><label for=\"sk-estimator-id-14\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=0, shuffle=True),\n",
       "             estimator=XGBClassifier(base_score=0.5, booster=&#x27;gbtree&#x27;,\n",
       "                                     callbacks=None, colsample_bylevel=0.5,\n",
       "                                     colsample_bynode=1, colsample_bytree=0.4,\n",
       "                                     early_stopping_rounds=None,\n",
       "                                     enable_categorical=False, eval_metric=None,\n",
       "                                     gamma=0, gpu_id=0, grow_policy=&#x27;depthwise&#x27;,\n",
       "                                     importance_type=None,\n",
       "                                     interaction_co...\n",
       "                                     max_depth=10, max_leaves=0,\n",
       "                                     min_child_weight=1, missing=nan,\n",
       "                                     monotone_constraints=&#x27;()&#x27;,\n",
       "                                     n_estimators=1000, n_jobs=0,\n",
       "                                     num_parallel_tree=1, predictor=&#x27;auto&#x27;,\n",
       "                                     random_state=0, reg_alpha=0, reg_lambda=1, ...),\n",
       "             param_grid={&#x27;colsample_bylevel&#x27;: [0.5, 0.7],\n",
       "                         &#x27;colsample_bytree&#x27;: [0.5, 0.4],\n",
       "                         &#x27;learning_rate&#x27;: [0.01], &#x27;max_depth&#x27;: [10, 30],\n",
       "                         &#x27;n_estimators&#x27;: [1000, 1500]},\n",
       "             scoring=&#x27;roc_auc&#x27;, verbose=-1)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-15\" type=\"checkbox\" ><label for=\"sk-estimator-id-15\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=0.5, booster=&#x27;gbtree&#x27;, callbacks=None,\n",
       "              colsample_bylevel=0.5, colsample_bynode=1, colsample_bytree=0.4,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric=None, gamma=0, gpu_id=0, grow_policy=&#x27;depthwise&#x27;,\n",
       "              importance_type=None, interaction_constraints=&#x27;&#x27;,\n",
       "              learning_rate=0.01, max_bin=256, max_cat_to_onehot=4,\n",
       "              max_delta_step=0, max_depth=10, max_leaves=0, min_child_weight=1,\n",
       "              missing=nan, monotone_constraints=&#x27;()&#x27;, n_estimators=1000,\n",
       "              n_jobs=0, num_parallel_tree=1, predictor=&#x27;auto&#x27;, random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, ...)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-16\" type=\"checkbox\" ><label for=\"sk-estimator-id-16\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=0.5, booster=&#x27;gbtree&#x27;, callbacks=None,\n",
       "              colsample_bylevel=0.5, colsample_bynode=1, colsample_bytree=0.4,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric=None, gamma=0, gpu_id=0, grow_policy=&#x27;depthwise&#x27;,\n",
       "              importance_type=None, interaction_constraints=&#x27;&#x27;,\n",
       "              learning_rate=0.01, max_bin=256, max_cat_to_onehot=4,\n",
       "              max_delta_step=0, max_depth=10, max_leaves=0, min_child_weight=1,\n",
       "              missing=nan, monotone_constraints=&#x27;()&#x27;, n_estimators=1000,\n",
       "              n_jobs=0, num_parallel_tree=1, predictor=&#x27;auto&#x27;, random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, ...)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=0, shuffle=True),\n",
       "             estimator=XGBClassifier(base_score=0.5, booster='gbtree',\n",
       "                                     callbacks=None, colsample_bylevel=0.5,\n",
       "                                     colsample_bynode=1, colsample_bytree=0.4,\n",
       "                                     early_stopping_rounds=None,\n",
       "                                     enable_categorical=False, eval_metric=None,\n",
       "                                     gamma=0, gpu_id=0, grow_policy='depthwise',\n",
       "                                     importance_type=None,\n",
       "                                     interaction_co...\n",
       "                                     max_depth=10, max_leaves=0,\n",
       "                                     min_child_weight=1, missing=nan,\n",
       "                                     monotone_constraints='()',\n",
       "                                     n_estimators=1000, n_jobs=0,\n",
       "                                     num_parallel_tree=1, predictor='auto',\n",
       "                                     random_state=0, reg_alpha=0, reg_lambda=1, ...),\n",
       "             param_grid={'colsample_bylevel': [0.5, 0.7],\n",
       "                         'colsample_bytree': [0.5, 0.4],\n",
       "                         'learning_rate': [0.01], 'max_depth': [10, 30],\n",
       "                         'n_estimators': [1000, 1500]},\n",
       "             scoring='roc_auc', verbose=-1)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing Grid search \n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Setting out parameter values\n",
    "params = { 'max_depth': [10, 30],\n",
    "           'learning_rate': [0.01],\n",
    "           'n_estimators': [1000, 1500],\n",
    "           'colsample_bytree': [0.5, 0.4],\n",
    "         'colsample_bylevel': [0.5, 0.7]}\n",
    "\n",
    "\n",
    "# Initiating GridSearch CV\n",
    "clf = GridSearchCV(estimator=xgc, \n",
    "                   param_grid=params,\n",
    "                   cv=cv_skf,\n",
    "                   scoring='roc_auc', \n",
    "                   verbose=-1)\n",
    "# Fitting GridSearch to our training data\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "af4474ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'colsample_bylevel': 0.5, 'colsample_bytree': 0.4, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 1000}\n"
     ]
    }
   ],
   "source": [
    "print(\"Best parameters:\", clf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "2ec5aeca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-16 {color: black;background-color: white;}#sk-container-id-16 pre{padding: 0;}#sk-container-id-16 div.sk-toggleable {background-color: white;}#sk-container-id-16 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-16 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-16 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-16 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-16 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-16 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-16 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-16 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-16 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-16 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-16 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-16 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-16 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-16 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-16 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-16 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-16 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-16 div.sk-item {position: relative;z-index: 1;}#sk-container-id-16 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-16 div.sk-item::before, #sk-container-id-16 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-16 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-16 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-16 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-16 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-16 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-16 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-16 div.sk-label-container {text-align: center;}#sk-container-id-16 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-16 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-16\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=0.5, booster=&#x27;gbtree&#x27;, callbacks=None,\n",
       "              colsample_bylevel=0.5, colsample_bynode=1, colsample_bytree=0.4,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric=None, gamma=0, gpu_id=0, grow_policy=&#x27;depthwise&#x27;,\n",
       "              importance_type=None, interaction_constraints=&#x27;&#x27;,\n",
       "              learning_rate=0.01, max_bin=256, max_cat_to_onehot=4,\n",
       "              max_delta_step=0, max_depth=5, max_leaves=0, min_child_weight=1,\n",
       "              missing=nan, monotone_constraints=&#x27;()&#x27;, n_estimators=2000,\n",
       "              n_jobs=0, num_parallel_tree=1, predictor=&#x27;auto&#x27;, random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-20\" type=\"checkbox\" checked><label for=\"sk-estimator-id-20\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=0.5, booster=&#x27;gbtree&#x27;, callbacks=None,\n",
       "              colsample_bylevel=0.5, colsample_bynode=1, colsample_bytree=0.4,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric=None, gamma=0, gpu_id=0, grow_policy=&#x27;depthwise&#x27;,\n",
       "              importance_type=None, interaction_constraints=&#x27;&#x27;,\n",
       "              learning_rate=0.01, max_bin=256, max_cat_to_onehot=4,\n",
       "              max_delta_step=0, max_depth=5, max_leaves=0, min_child_weight=1,\n",
       "              missing=nan, monotone_constraints=&#x27;()&#x27;, n_estimators=2000,\n",
       "              n_jobs=0, num_parallel_tree=1, predictor=&#x27;auto&#x27;, random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', callbacks=None,\n",
       "              colsample_bylevel=0.5, colsample_bynode=1, colsample_bytree=0.4,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric=None, gamma=0, gpu_id=0, grow_policy='depthwise',\n",
       "              importance_type=None, interaction_constraints='',\n",
       "              learning_rate=0.01, max_bin=256, max_cat_to_onehot=4,\n",
       "              max_delta_step=0, max_depth=5, max_leaves=0, min_child_weight=1,\n",
       "              missing=nan, monotone_constraints='()', n_estimators=2000,\n",
       "              n_jobs=0, num_parallel_tree=1, predictor='auto', random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, ...)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initiating optimized version\n",
    "xgc = xgb.XGBClassifier(\n",
    "    tree_method=\"gpu_hist\", colsample_bylevel=0.5, colsample_bytree=0.4, learning_rate=0.01, max_depth=5, n_estimators=2000\n",
    ")\n",
    "\n",
    "# Fitting the model\n",
    "xgc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "2e57638b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.20508575],\n",
       "       [0.07659256],\n",
       "       [0.39953434],\n",
       "       ...,\n",
       "       [0.27764517],\n",
       "       [0.14886056],\n",
       "       [0.0887237 ]], dtype=float32)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Optimized XBG predictions\n",
    "y_pred_xn= xgc.predict_proba(X_test)\n",
    "\n",
    "y_pred_xn= y_pred_xn[:,1].reshape(-1,1)\n",
    "\n",
    "y_pred_xn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "73f60ba1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7115590158250132"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Optimized XGB score\n",
    "roc_auc_score(y_test, y_pred_xn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bace4165",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68041e6a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
